---
title: ttok
---

--8<-- "includes/lavori_in_corso.md"

# ttok

**`ttok`** Ã¨ un altro strumento creato da **Simon Willison**, per contare il numero di token di un testo e/o troncarlo in base a un numero desiderato di questi.

!!! note "Cosa sono i token?"

    I **token** sono le unitÃ  base in cui gli LLM suddividono il testo per elaborarlo. Un token puÃ² essere una parola intera, parte di una parola, un carattere di punteggiatura o anche uno spazio. Ad esempio, la frase "Ciao mondo!" potrebbe essere divisa in 3 token: "Ciao", " mondo", "!".

Ãˆ fondamentale conoscere il numero di token perchÃ© i modelli LLM hanno un limite massimo di token che possono elaborare, in input e output. Inoltre il **costo** dell'**utilizzo** di un modello LLM Ã¨ spesso calcolato in base al numero di token elaborati.

`ttok` Ã¨ scritto in Python e si puÃ² installare con `pip` o con `uv`:

```bash
pip install ttok
```

```bash
uv tool install ttok
```

Il modello di default utilizzato per il conteggio dei token Ã¨ quello di GPT-3.5 e GPT-4.

## Utilizzo

### Base

Il comando base si puÃ² lanciare cosÃ¬:

```bash
ttok Ciao mondo
```

In output si ottiene il numero di token:

```bash
3
```

Oppure Ã¨ possibile fargli leggere l'output di un comando, come ad esempio `curl` e conteggiare il numero di token della pagina web su Wikipedia dedicata a Aaron Swartz:

```bash
curl -kL 'https://en.wikipedia.org/wiki/Aaron_Swartz' | ttok
```

In questo caso si hanno circa `230.000` token di output. Questo si puÃ² passare a un `LLM` tramite [`llm` cli](../llm_cli/index.md) per chiedere di riassumere il testo per un messaggio da inviare in chat:

```
curl -kL 'https://en.wikipedia.org/wiki/Aaron_Swartz' | \
llm "mi scrivi un messaggio breve per stimolare le persone a scoprire chi Ã¨ Aaron. Lo invierÃ² in chat" | ttok
```

In output si ottiene qualcosa come il testo di sotto, che Ã¨ lungo circa `70` token:

```text {. }
Hai mai sentito parlare di Aaron Swartz? ðŸ¤” Era un genio, un attivista e un pioniere del web. La sua storia Ã¨ incredibile e ti farÃ  riflettere sul futuro di internet e della conoscenza. Scoprilo anche tu! ðŸ˜‰"
```

Conoscendo il numero di token di input e di output, in base al modello di LLM scelto, si puÃ² calcolare il [costo del servizio](#costo-dei-modelli-llm-per-numero-di-token).

### Troncare il testo a un certo numero di token

Se si vuole troncare il testo a un certo numero di token, si puÃ² usare l'opzione `-t` seguita dal numero di token desiderato. Ad esempio, per troncare il testo a `10` token:

```bash
ttok -t 10 "Ciao mondo, questo Ã¨ un testo di esempio che voglio troncare a dieci token."
```

In output si ottiene il testo troncato:

```text {.wordwrap-code }
Ciao mondo, questo Ã¨ un testo di
```

### Visualizzare i token

Per visualizzare i token di un testo, si puÃ² usare l'opzione `--encode`:

```bash
ttok "Ciao mondo, questo Ã¨ un testo di esempio" --encode
```

In output si ottengono gli ID dei token (dei 13 token del testo di esempio):

```text
34 23332 70809 11 34560 11676 653 1296 78 1891 1560 3342 822
```

Per convertire questi ID in testo leggibile, si puÃ² usare l'opzione `--decode`:

```bash
ttok "34 23332 70809 11 34560 11676 653 1296 78 1891 1560 3342 822" --decode
```

## Costo dei modelli LLM per numero di token

Simon Willison - Ã¨ sempre bene rinnovare una volta al giorno **grazie Simon** -  ha realizzato un [calcolatore di costi per token e modello](https://www.llm-prices.com/), che permette di calcolare il costo del servizio.

[![](images/token_price.png)](https://www.llm-prices.com)
